{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "FEATS_EXCLUDED = [\n",
    "    \"ID\",\"tradeMoney\"\n",
    "    ]\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "# rmse\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "\n",
    "    plt.figure(figsize=(8, 10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances.png')\n",
    "\n",
    "# reduce memory\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import optuna\n",
    "\n",
    "FEATS_EXCLUDED = [\n",
    "    \"ID\",\"tradeMoney\"\n",
    "    ]\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def objective(trial):\n",
    "        num_folds = 11\n",
    "        \n",
    "        train_x, train_y = train_df[feats], train_df['tradeMoney']\n",
    "        #data, target = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
    "        '''dtrain = lgb.Dataset(train_x, label=train_y)'''\n",
    "             \n",
    "        lgbm_train = lgb.Dataset(train_x,\n",
    "                                 train_y,\n",
    "                                  free_raw_data=False\n",
    "                                  )\n",
    "\n",
    "        params = {'objective': 'regression',\n",
    "                  'metric': 'rmse',\n",
    "                  'verbosity': -1,\n",
    "                  \"learning_rate\": trial.suggest_uniform('learning_rate', 0.001, 1),\n",
    "                  \n",
    "                  'device': 'gpu',\n",
    "                  'gpu_platform_id': 1,\n",
    "                  'gpu_device_id': 0,\n",
    "                  'num_thread' : 1,\n",
    "                  'sparse_threshold' : 1,\n",
    "                  \n",
    "                  'seed': 2779,\n",
    "                  #'boosting_type': trial.suggest_categorical('boosting', ['gbdt',  'goss']),\n",
    "                  'num_leaves': trial.suggest_int('num_leaves', 16, 200),\n",
    "                  #'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.001, 1),\n",
    "                  'subsample': trial.suggest_uniform('subsample', 0.001, 1),\n",
    "                  'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
    "                  'reg_alpha': trial.suggest_uniform('reg_alpha', 0, 10),\n",
    "                  # 'reg_lambda': trial.suggest_uniform('reg_lambda', 0, 10),\n",
    "                  #'min_split_gain': trial.suggest_uniform('min_split_gain', 0, 10),\n",
    "                  #'min_child_weight': trial.suggest_uniform('min_child_weight', 0, 45),\n",
    "                  #'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 16, 64)\n",
    "                  \n",
    "                  'min_child_samples' : trial.suggest_int('min_child_samples', 1, 200),\n",
    "                  #'num_iterations': trial.suggest_uniform('num_iterations', 1, 5000),\n",
    "                  'feature_fraction' : trial.suggest_uniform('feature_fraction', 0.001, 1),\n",
    "                  #'random_state': trial.suggest_int('random_state', 1, 5000),\n",
    "                  #'max_bin' :  trial.suggest_int('random_state', 1, 256)\n",
    "                  }\n",
    "\n",
    "        '''if params['boosting_type'] == 'dart':\n",
    "            params['drop_rate'] = trial.suggest_loguniform('drop_rate', 1e-8, 1.0)\n",
    "            params['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)\n",
    "        if params['boosting_type'] == 'goss':\n",
    "            params['top_rate'] = trial.suggest_uniform('top_rate', 0.0, 1.0)\n",
    "            params['other_rate'] = trial.suggest_uniform('other_rate', 0.0, 1.0 - params['top_rate'])'''\n",
    "\n",
    "\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=47)\n",
    "        #folds = KFold(n_splits= num_folds, shuffle=True, random_state=47)\n",
    "\n",
    "\n",
    "        clf = lgb.cv(\n",
    "                        params,\n",
    "                        lgbm_train,\n",
    "                        metrics=['rmse'],\n",
    "                        nfold=num_folds,\n",
    "                        folds=folds.split(train_df[feats], train_y),\n",
    "                        num_boost_round=10000,\n",
    "                        early_stopping_rounds= 500,\n",
    "                        verbose_eval=100,\n",
    "                        seed=47\n",
    "            \n",
    "                         )\n",
    "        gc.collect()\n",
    "        return clf['rmse-mean'][-1]\n",
    "\n",
    "        \n",
    "        '''gbm = lgb.train(params, dtrain)\n",
    "        preds = gbm.predict(train_x)\n",
    "        pred_labels = np.rint(preds)\n",
    "        error =  rmse(train_y,preds)\n",
    "        #accuracy = sklearn.metrics.accuracy_score(test_y, pred_labels)\n",
    "        return error'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 8.02 MB\n",
      "Decreased by 79.9%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in less\n",
      "\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in less\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage after optimization is: 0.49 MB\n",
      "Decreased by 79.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning:\n",
      "\n",
      "The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=11.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tcv_agg's rmse: 1988.03 + 550.864\n",
      "[200]\tcv_agg's rmse: 2000.33 + 533.573\n",
      "[300]\tcv_agg's rmse: 2015.66 + 529.546\n",
      "[400]\tcv_agg's rmse: 2022.48 + 529.901\n"
     ]
    }
   ],
   "source": [
    "with timer(\"split train & test\"):\n",
    "        train_df = reduce_mem_usage(pd.read_csv('train_clean4.csv',encoding='gbk'))\n",
    "        test_df = reduce_mem_usage(pd.read_csv('test_clean4.csv',encoding='gbk'))\n",
    "        \n",
    "        train_df = train_df[train_df.tradeMoney < 100000]\n",
    "        train_df = train_df[train_df.tradeMoney > 500]\n",
    "\n",
    "        train_df = train_df[train_df.area < 2500]\n",
    "       \n",
    "        feature_importance_df = pd.DataFrame()\n",
    "        feats = [f for f in train_df.columns if f not in FEATS_EXCLUDED]\n",
    "        \n",
    "        study = optuna.create_study()\n",
    "        study.optimize(objective, n_trials=1000)\n",
    "\n",
    "        print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "\n",
    "        print('Best trial:')\n",
    "        trial = study.best_trial\n",
    "\n",
    "        print('  Value: {}'.format(trial.value))\n",
    "\n",
    "        print('  Params: ')\n",
    "        for key, value in trial.params.items():\n",
    "            print('    {}: {}'.format(key, value))\n",
    "        \n",
    "        hist_df = study.trials_dataframe()\n",
    "        hist_df.to_csv(\"optuna_result_lgbm.csv\")\n",
    "\n",
    "        del df\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
