{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgboost\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso, LarsCV, RidgeCV, Lars\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import datetime\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import scipy\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d2a5ca4b3bdef8721219199fa32f8aa269b0a0ea"
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (8,4)\n",
    "rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "f6cd062118a4b6367524a458e90b41bec8f5a3f8"
   },
   "outputs": [],
   "source": [
    "DEBUG = False\n",
    "REF_DATE = datetime.datetime.strptime('2019-6-3', '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "df04c695a9e7cd33f607417113cb5087236612c2"
   },
   "outputs": [],
   "source": [
    "def skip_func(i, p=0.1, debug=DEBUG):\n",
    "    if debug == True:\n",
    "        return (i>0 and random.random()>p)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "5ca82b1e416084bd455edc07ed2a0cfd59d3b22f"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "092dbb6a27d0c3ec7d582320f3d688092f76065c"
   },
   "source": [
    "<a id='modeling'></a>\n",
    "\n",
    "## Modeling\n",
    "\n",
    "Here we use [out of fold stacking ensemble](https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-for-ensemble-models/). The architecture is as followed:\n",
    "\n",
    "**Layer 1**:\n",
    "* 2 lightgbm\n",
    "* 1 xgboost\n",
    "* 1 catboost\n",
    "* 1 dense neural network\n",
    "\n",
    "**Layer 2**:\n",
    "* Lasso regression\n",
    "* Ridge regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\n\\nFEATS_EXCLUDED = [\\n    \"ID\",\"tradeMoney\"]\\ntrain = pd.read_csv(\\'train_clean4.csv\\',encoding = \\'gbk\\')\\ntest = pd.read_csv(\\'test_clean4.csv\\',encoding = \\'gbk\\')\\n\\ntrain = train[train.tradeMoney < 100000]\\ntrain = train[train.tradeMoney > 500]\\n\\ntrain = train[train.area < 2500]\\n\\nfeatures = [c for c in train.columns if c not in FEATS_EXCLUDED]\\n\\ntarget = train[\\'tradeMoney\\']'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''%%time\n",
    "\n",
    "FEATS_EXCLUDED = [\n",
    "    \"ID\",\"tradeMoney\"]\n",
    "train = pd.read_csv('train_clean4.csv',encoding = 'gbk')\n",
    "test = pd.read_csv('test_clean4.csv',encoding = 'gbk')\n",
    "\n",
    "train = train[train.tradeMoney < 100000]\n",
    "train = train[train.tradeMoney > 500]\n",
    "\n",
    "train = train[train.area < 2500]\n",
    "\n",
    "features = [c for c in train.columns if c not in FEATS_EXCLUDED]\n",
    "\n",
    "target = train['tradeMoney']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATS_EXCLUDED = [\"ID\",\"tradeMoney\"]\n",
    "train = pd.read_csv('train_clean.csv',encoding = 'gbk')\n",
    "test = pd.read_csv('test_clean.csv',encoding = 'gbk')\n",
    "features = [c for c in train.columns if c not in FEATS_EXCLUDED]\n",
    "target = train['tradeMoney']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c97eb36f6c18eacde14ee15e1d797111df8d8cc5"
   },
   "source": [
    "### First layer\n",
    "#### Tree-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "883c8336a77e146defbc92ebc4276147af1145cd"
   },
   "outputs": [],
   "source": [
    "# List of model to use\n",
    "if DEBUG == True:\n",
    "    ITERATIONS = 1\n",
    "else:\n",
    "    ITERATIONS = 200000\n",
    "lgb1 = lgb.LGBMRegressor(\n",
    "                        objective= 'regression_l2',\n",
    "                        num_leaves=111,\n",
    "                        max_depth=9,\n",
    "                        learning_rate=0.0035591640406098355,\n",
    "                        n_estimators=ITERATIONS,\n",
    "                        min_child_samples=63,\n",
    "                        subsample=0.6815424617328696,\n",
    "                        subsample_freq=1,\n",
    "                        feature_fraction=0.5020039195436962,\n",
    "                        reg_lambda=8.570580601734264,\n",
    "                        random_state=2333,\n",
    "                        n_jobs=4,\n",
    "                        metrics='rmse',\n",
    "                          device = 'gpu',\n",
    "                          gpu_platform_id= 1,\n",
    "                          gpu_device_id=0,\n",
    "                          num_thread = 1,\n",
    "                          sparse_threshold= 1)\n",
    "\n",
    "\n",
    "\n",
    "xgb1 = xgb.XGBRegressor(learning_rate= 0.0035591640406098355,\n",
    "                        booster= 'gbtree',\n",
    "                        alpha = 1.0239095745311145e-08,\n",
    "                        boosting= 'gbdt',\n",
    "                        num_leaves= 31,\n",
    "                        colsample_bytree= 0.5406862297709868,\n",
    "                        subsample= 0.9594952525792275,\n",
    "                        max_depth= 5,\n",
    "                        reg_lambda= 3.143121436123109,\n",
    "                        eta= 2.9162386740282797e-07,\n",
    "                        gamma= 6.015464829655147e-07,\n",
    "                        grow_policy= 'depthwise',\n",
    "                       random_state=2333,\n",
    "                        )\n",
    "\n",
    "cb1 = cb.CatBoostRegressor(iterations=100000,\n",
    "                                 learning_rate=0.004,\n",
    "                                 depth=5,\n",
    "                                 eval_metric='RMSE',\n",
    "                                 colsample_bylevel=0.8,\n",
    "                                 random_seed = 2333,\n",
    "                                 bagging_temperature = 0.2,\n",
    "                                 metric_period = None,\n",
    "                                 early_stopping_rounds=200\n",
    "                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "e9b8682c16601ea57fb80535f8cff0ba283ce80d"
   },
   "outputs": [],
   "source": [
    "if DEBUG==True:\n",
    "    N_FOLDS=2\n",
    "else:\n",
    "    N_FOLDS=11\n",
    "layer1_models = [lgb1,xgb1,cb1 ]#, ada1]\n",
    "layer1_names = ['lightgbm1','xgboost', 'catboost1']#, 'adaboost1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "3e422ec61d402e712fe983df24b4ecb00fb26057"
   },
   "outputs": [],
   "source": [
    "oof_train = np.zeros(shape=(len(train),len(layer1_models)))\n",
    "oof_test = np.zeros(shape=(len(test),len(layer1_models)))\n",
    "\n",
    "# Recording results\n",
    "layer1_score = []\n",
    "feature_importance = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e52e62067c5e7340d22a69fd0ef93315ea86ff81",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training lightgbm1\n",
      "Fold no 1/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1198.33\tvalid_1's rmse: 1468.01\n",
      "[2000]\ttraining's rmse: 1083.47\tvalid_1's rmse: 1382.06\n",
      "[3000]\ttraining's rmse: 1025.74\tvalid_1's rmse: 1357.78\n",
      "[4000]\ttraining's rmse: 980.847\tvalid_1's rmse: 1338.82\n",
      "[5000]\ttraining's rmse: 943.857\tvalid_1's rmse: 1326.49\n",
      "[6000]\ttraining's rmse: 911.964\tvalid_1's rmse: 1315.02\n",
      "[7000]\ttraining's rmse: 884.452\tvalid_1's rmse: 1306.6\n",
      "[8000]\ttraining's rmse: 859.431\tvalid_1's rmse: 1299.63\n",
      "[9000]\ttraining's rmse: 836.759\tvalid_1's rmse: 1294.52\n",
      "[10000]\ttraining's rmse: 816.115\tvalid_1's rmse: 1289.79\n",
      "[11000]\ttraining's rmse: 797.276\tvalid_1's rmse: 1285.53\n",
      "[12000]\ttraining's rmse: 779.104\tvalid_1's rmse: 1281.24\n",
      "[13000]\ttraining's rmse: 762.812\tvalid_1's rmse: 1278.41\n",
      "[14000]\ttraining's rmse: 747.605\tvalid_1's rmse: 1275.73\n",
      "[15000]\ttraining's rmse: 732.538\tvalid_1's rmse: 1272.44\n",
      "[16000]\ttraining's rmse: 718.803\tvalid_1's rmse: 1269.46\n",
      "[17000]\ttraining's rmse: 705.757\tvalid_1's rmse: 1267.42\n",
      "[18000]\ttraining's rmse: 693.302\tvalid_1's rmse: 1265.7\n",
      "[19000]\ttraining's rmse: 681.418\tvalid_1's rmse: 1264.47\n",
      "[20000]\ttraining's rmse: 670.325\tvalid_1's rmse: 1262.98\n",
      "Early stopping, best iteration is:\n",
      "[20257]\ttraining's rmse: 667.535\tvalid_1's rmse: 1262.52\n",
      "Fold no 2/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1214.02\tvalid_1's rmse: 1235.25\n",
      "[2000]\ttraining's rmse: 1098.48\tvalid_1's rmse: 1188.57\n",
      "[3000]\ttraining's rmse: 1038.37\tvalid_1's rmse: 1169.47\n",
      "[4000]\ttraining's rmse: 992.599\tvalid_1's rmse: 1157.56\n",
      "[5000]\ttraining's rmse: 954.879\tvalid_1's rmse: 1148\n",
      "[6000]\ttraining's rmse: 922.731\tvalid_1's rmse: 1142.55\n",
      "[7000]\ttraining's rmse: 894.235\tvalid_1's rmse: 1137.64\n",
      "[8000]\ttraining's rmse: 868.934\tvalid_1's rmse: 1132.79\n",
      "[9000]\ttraining's rmse: 846.044\tvalid_1's rmse: 1129.81\n",
      "[10000]\ttraining's rmse: 824.48\tvalid_1's rmse: 1125.84\n",
      "[11000]\ttraining's rmse: 804.769\tvalid_1's rmse: 1123.77\n",
      "[12000]\ttraining's rmse: 786.736\tvalid_1's rmse: 1121.43\n",
      "[13000]\ttraining's rmse: 769.848\tvalid_1's rmse: 1119.06\n",
      "Early stopping, best iteration is:\n",
      "[13608]\ttraining's rmse: 760.342\tvalid_1's rmse: 1118.19\n",
      "Fold no 3/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1212.57\tvalid_1's rmse: 1285.82\n",
      "[2000]\ttraining's rmse: 1095.08\tvalid_1's rmse: 1236.36\n",
      "[3000]\ttraining's rmse: 1034.95\tvalid_1's rmse: 1217.88\n",
      "[4000]\ttraining's rmse: 988.112\tvalid_1's rmse: 1207.32\n",
      "[5000]\ttraining's rmse: 950.242\tvalid_1's rmse: 1200.88\n",
      "[6000]\ttraining's rmse: 917.032\tvalid_1's rmse: 1197.15\n",
      "Early stopping, best iteration is:\n",
      "[6201]\ttraining's rmse: 911.055\tvalid_1's rmse: 1196.39\n",
      "Fold no 4/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1215.63\tvalid_1's rmse: 1201.87\n",
      "[2000]\ttraining's rmse: 1099.77\tvalid_1's rmse: 1177.82\n",
      "[3000]\ttraining's rmse: 1039.06\tvalid_1's rmse: 1169.59\n",
      "Early stopping, best iteration is:\n",
      "[3641]\ttraining's rmse: 1008.4\tvalid_1's rmse: 1166.35\n",
      "Fold no 5/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1229.25\tvalid_1's rmse: 1089.52\n",
      "[2000]\ttraining's rmse: 1112.7\tvalid_1's rmse: 1021.9\n",
      "[3000]\ttraining's rmse: 1053.52\tvalid_1's rmse: 998.715\n",
      "[4000]\ttraining's rmse: 1007.96\tvalid_1's rmse: 985.195\n",
      "[5000]\ttraining's rmse: 968.452\tvalid_1's rmse: 976.273\n",
      "[6000]\ttraining's rmse: 935.199\tvalid_1's rmse: 969.501\n",
      "[7000]\ttraining's rmse: 906.728\tvalid_1's rmse: 964.115\n",
      "[8000]\ttraining's rmse: 881.314\tvalid_1's rmse: 960.794\n",
      "[9000]\ttraining's rmse: 857.953\tvalid_1's rmse: 957.174\n",
      "Early stopping, best iteration is:\n",
      "[9195]\ttraining's rmse: 853.825\tvalid_1's rmse: 956.706\n",
      "Fold no 6/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1220.88\tvalid_1's rmse: 1194.11\n",
      "[2000]\ttraining's rmse: 1106.2\tvalid_1's rmse: 1133.05\n",
      "[3000]\ttraining's rmse: 1048.17\tvalid_1's rmse: 1105.4\n",
      "[4000]\ttraining's rmse: 1002.91\tvalid_1's rmse: 1087.83\n",
      "[5000]\ttraining's rmse: 965.501\tvalid_1's rmse: 1074.92\n",
      "[6000]\ttraining's rmse: 933.108\tvalid_1's rmse: 1064.49\n",
      "[7000]\ttraining's rmse: 904.76\tvalid_1's rmse: 1055.68\n",
      "[8000]\ttraining's rmse: 879.34\tvalid_1's rmse: 1049.25\n",
      "[9000]\ttraining's rmse: 856.666\tvalid_1's rmse: 1044.12\n",
      "[10000]\ttraining's rmse: 835.198\tvalid_1's rmse: 1038.23\n",
      "[11000]\ttraining's rmse: 815.844\tvalid_1's rmse: 1033.72\n",
      "[12000]\ttraining's rmse: 797.763\tvalid_1's rmse: 1029.76\n",
      "[13000]\ttraining's rmse: 780.611\tvalid_1's rmse: 1026.87\n",
      "[14000]\ttraining's rmse: 764.851\tvalid_1's rmse: 1024.4\n",
      "[15000]\ttraining's rmse: 749.718\tvalid_1's rmse: 1021.35\n",
      "[16000]\ttraining's rmse: 735.712\tvalid_1's rmse: 1018.55\n",
      "[17000]\ttraining's rmse: 722.772\tvalid_1's rmse: 1016.19\n",
      "[18000]\ttraining's rmse: 710.288\tvalid_1's rmse: 1013.84\n",
      "[19000]\ttraining's rmse: 698.009\tvalid_1's rmse: 1011.64\n",
      "[20000]\ttraining's rmse: 686.583\tvalid_1's rmse: 1009.47\n",
      "[21000]\ttraining's rmse: 675.464\tvalid_1's rmse: 1007.57\n",
      "[22000]\ttraining's rmse: 664.824\tvalid_1's rmse: 1005.46\n",
      "[23000]\ttraining's rmse: 654.682\tvalid_1's rmse: 1003.66\n",
      "Early stopping, best iteration is:\n",
      "[23095]\ttraining's rmse: 653.765\tvalid_1's rmse: 1003.54\n",
      "Fold no 7/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1209.24\tvalid_1's rmse: 1371.76\n",
      "[2000]\ttraining's rmse: 1096.26\tvalid_1's rmse: 1289.71\n",
      "[3000]\ttraining's rmse: 1038.32\tvalid_1's rmse: 1258.3\n",
      "[4000]\ttraining's rmse: 993.863\tvalid_1's rmse: 1236.25\n",
      "[5000]\ttraining's rmse: 957.017\tvalid_1's rmse: 1219.78\n",
      "[6000]\ttraining's rmse: 924.629\tvalid_1's rmse: 1207.54\n",
      "[7000]\ttraining's rmse: 896.883\tvalid_1's rmse: 1198.51\n",
      "[8000]\ttraining's rmse: 871.768\tvalid_1's rmse: 1190.67\n",
      "[9000]\ttraining's rmse: 848.52\tvalid_1's rmse: 1184.79\n",
      "[10000]\ttraining's rmse: 826.918\tvalid_1's rmse: 1179.84\n",
      "[11000]\ttraining's rmse: 807.32\tvalid_1's rmse: 1175.8\n",
      "[12000]\ttraining's rmse: 789.271\tvalid_1's rmse: 1172.58\n",
      "[13000]\ttraining's rmse: 772.576\tvalid_1's rmse: 1169.94\n",
      "[14000]\ttraining's rmse: 756.962\tvalid_1's rmse: 1167.94\n",
      "[15000]\ttraining's rmse: 741.816\tvalid_1's rmse: 1166.54\n",
      "Early stopping, best iteration is:\n",
      "[15239]\ttraining's rmse: 738.357\tvalid_1's rmse: 1165.51\n",
      "Fold no 8/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1206.75\tvalid_1's rmse: 1331.81\n",
      "[2000]\ttraining's rmse: 1089.24\tvalid_1's rmse: 1292.29\n",
      "[3000]\ttraining's rmse: 1030.28\tvalid_1's rmse: 1281.04\n",
      "[4000]\ttraining's rmse: 985.566\tvalid_1's rmse: 1273.47\n",
      "[5000]\ttraining's rmse: 946.738\tvalid_1's rmse: 1267.58\n",
      "[6000]\ttraining's rmse: 914.668\tvalid_1's rmse: 1262.85\n",
      "[7000]\ttraining's rmse: 886.232\tvalid_1's rmse: 1259.05\n",
      "[8000]\ttraining's rmse: 860.541\tvalid_1's rmse: 1255.57\n",
      "Early stopping, best iteration is:\n",
      "[8081]\ttraining's rmse: 858.68\tvalid_1's rmse: 1255.04\n",
      "Fold no 9/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1218.01\tvalid_1's rmse: 1220.33\n",
      "[2000]\ttraining's rmse: 1104.82\tvalid_1's rmse: 1139.73\n",
      "[3000]\ttraining's rmse: 1045.72\tvalid_1's rmse: 1112.26\n",
      "[4000]\ttraining's rmse: 998.898\tvalid_1's rmse: 1093.96\n",
      "[5000]\ttraining's rmse: 960.531\tvalid_1's rmse: 1081.81\n",
      "[6000]\ttraining's rmse: 927.083\tvalid_1's rmse: 1072.85\n",
      "[7000]\ttraining's rmse: 898.152\tvalid_1's rmse: 1066.78\n",
      "[8000]\ttraining's rmse: 871.911\tvalid_1's rmse: 1061.87\n",
      "[9000]\ttraining's rmse: 848.473\tvalid_1's rmse: 1058.61\n",
      "[10000]\ttraining's rmse: 826.855\tvalid_1's rmse: 1055.48\n",
      "[11000]\ttraining's rmse: 807.403\tvalid_1's rmse: 1053.89\n",
      "Early stopping, best iteration is:\n",
      "[11371]\ttraining's rmse: 800.413\tvalid_1's rmse: 1053.38\n",
      "Fold no 10/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1215.98\tvalid_1's rmse: 1287.85\n",
      "[2000]\ttraining's rmse: 1100.39\tvalid_1's rmse: 1223.84\n",
      "[3000]\ttraining's rmse: 1040.9\tvalid_1's rmse: 1198.36\n",
      "[4000]\ttraining's rmse: 994.838\tvalid_1's rmse: 1182.57\n",
      "[5000]\ttraining's rmse: 956.928\tvalid_1's rmse: 1171.23\n",
      "[6000]\ttraining's rmse: 924.512\tvalid_1's rmse: 1162.38\n",
      "[7000]\ttraining's rmse: 895.871\tvalid_1's rmse: 1156.06\n",
      "[8000]\ttraining's rmse: 870.046\tvalid_1's rmse: 1151.14\n",
      "[9000]\ttraining's rmse: 846.769\tvalid_1's rmse: 1146.87\n",
      "[10000]\ttraining's rmse: 825.691\tvalid_1's rmse: 1143.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11000]\ttraining's rmse: 805.913\tvalid_1's rmse: 1141.16\n",
      "[12000]\ttraining's rmse: 787.443\tvalid_1's rmse: 1139.97\n",
      "[13000]\ttraining's rmse: 770.75\tvalid_1's rmse: 1138.5\n",
      "Early stopping, best iteration is:\n",
      "[12947]\ttraining's rmse: 771.637\tvalid_1's rmse: 1138.38\n",
      "Fold no 11/11\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[1000]\ttraining's rmse: 1186.58\tvalid_1's rmse: 1682.98\n",
      "[2000]\ttraining's rmse: 1076.13\tvalid_1's rmse: 1540.81\n",
      "[3000]\ttraining's rmse: 1018.22\tvalid_1's rmse: 1498.46\n",
      "[4000]\ttraining's rmse: 973.476\tvalid_1's rmse: 1475.42\n",
      "[5000]\ttraining's rmse: 936.255\tvalid_1's rmse: 1461.14\n",
      "[6000]\ttraining's rmse: 904.533\tvalid_1's rmse: 1450.37\n",
      "[7000]\ttraining's rmse: 877.242\tvalid_1's rmse: 1441.54\n",
      "[8000]\ttraining's rmse: 852.611\tvalid_1's rmse: 1435.64\n",
      "[9000]\ttraining's rmse: 830.42\tvalid_1's rmse: 1429.38\n",
      "[10000]\ttraining's rmse: 810.11\tvalid_1's rmse: 1424.82\n",
      "[11000]\ttraining's rmse: 791.164\tvalid_1's rmse: 1421.6\n",
      "[12000]\ttraining's rmse: 773.473\tvalid_1's rmse: 1418.85\n",
      "[13000]\ttraining's rmse: 757.219\tvalid_1's rmse: 1415.76\n",
      "[14000]\ttraining's rmse: 741.749\tvalid_1's rmse: 1413.79\n",
      "[15000]\ttraining's rmse: 727.013\tvalid_1's rmse: 1411.36\n",
      "[16000]\ttraining's rmse: 713.506\tvalid_1's rmse: 1409.46\n",
      "Early stopping, best iteration is:\n",
      "[16539]\ttraining's rmse: 706.183\tvalid_1's rmse: 1408.4\n",
      "Training CV score: 0.89490\n",
      "\n",
      "\n",
      "Training xgboost\n",
      "Fold no 1/11\n",
      "[0]\tvalidation_0-rmse:3052.09\tvalidation_1-rmse:3362.22\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:752.762\tvalidation_1-rmse:1455.9\n",
      "Fold no 2/11\n",
      "[0]\tvalidation_0-rmse:3000.21\tvalidation_1-rmse:2919.04\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:741.125\tvalidation_1-rmse:1209.83\n",
      "Fold no 3/11\n",
      "[0]\tvalidation_0-rmse:3148.43\tvalidation_1-rmse:3000.13\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:754.529\tvalidation_1-rmse:1262.68\n",
      "Fold no 4/11\n",
      "[0]\tvalidation_0-rmse:3211.51\tvalidation_1-rmse:2962.57\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:768.673\tvalidation_1-rmse:1294.35\n",
      "Fold no 5/11\n",
      "[0]\tvalidation_0-rmse:3054.08\tvalidation_1-rmse:2847.36\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:771.207\tvalidation_1-rmse:1014.87\n",
      "Fold no 6/11\n",
      "[0]\tvalidation_0-rmse:3054.08\tvalidation_1-rmse:2820.08\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:742.662\tvalidation_1-rmse:1117.78\n",
      "Fold no 7/11\n",
      "[0]\tvalidation_0-rmse:3007.4\tvalidation_1-rmse:3113.63\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:776.915\tvalidation_1-rmse:1371.74\n",
      "Fold no 8/11\n",
      "[0]\tvalidation_0-rmse:3034.1\tvalidation_1-rmse:2938.72\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:754.638\tvalidation_1-rmse:1329.04\n",
      "Fold no 9/11\n",
      "[0]\tvalidation_0-rmse:3015.52\tvalidation_1-rmse:2903.37\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:762.519\tvalidation_1-rmse:1158.87\n",
      "Fold no 10/11\n",
      "[0]\tvalidation_0-rmse:3002.46\tvalidation_1-rmse:2983.74\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:772.439\tvalidation_1-rmse:1218.37\n",
      "Fold no 11/11\n",
      "[0]\tvalidation_0-rmse:3022.71\tvalidation_1-rmse:3734.85\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 200 rounds.\n",
      "[99]\tvalidation_0-rmse:743.607\tvalidation_1-rmse:1540.57\n",
      "Training CV score: 0.87345\n",
      "\n",
      "\n",
      "Training catboost1\n",
      "Fold no 1/11\n",
      "0:\tlearn: 5903.1401382\ttest: 5903.1401382\ttest1: 6240.0543879\tbest: 6240.0543879 (0)\ttotal: 81.9ms\tremaining: 2h 16m 31s\n",
      "1000:\tlearn: 1466.4736580\ttest: 1466.4736580\ttest1: 1657.5153620\tbest: 1657.5153620 (1000)\ttotal: 40.4s\tremaining: 1h 6m 40s\n",
      "2000:\tlearn: 1350.7974923\ttest: 1350.7974923\ttest1: 1551.9908119\tbest: 1551.9908119 (2000)\ttotal: 1m 19s\tremaining: 1h 4m 55s\n",
      "3000:\tlearn: 1292.5225247\ttest: 1292.5225247\ttest1: 1515.9329410\tbest: 1515.9329410 (3000)\ttotal: 1m 58s\tremaining: 1h 3m 43s\n",
      "4000:\tlearn: 1246.4989822\ttest: 1246.4989822\ttest1: 1488.8720137\tbest: 1488.8720137 (4000)\ttotal: 2m 35s\tremaining: 1h 2m 15s\n",
      "5000:\tlearn: 1208.9964438\ttest: 1208.9964438\ttest1: 1465.7225955\tbest: 1465.7225955 (5000)\ttotal: 3m 13s\tremaining: 1h 1m 23s\n",
      "6000:\tlearn: 1177.1946867\ttest: 1177.1946867\ttest1: 1450.5962649\tbest: 1450.5962649 (6000)\ttotal: 3m 53s\tremaining: 1h 53s\n",
      "7000:\tlearn: 1153.5361165\ttest: 1153.5361165\ttest1: 1439.2200033\tbest: 1439.2200033 (7000)\ttotal: 4m 32s\tremaining: 1h 13s\n",
      "8000:\tlearn: 1133.1157241\ttest: 1133.1157241\ttest1: 1429.4221702\tbest: 1429.3870451 (7983)\ttotal: 5m 10s\tremaining: 59m 26s\n",
      "9000:\tlearn: 1116.3468291\ttest: 1116.3468291\ttest1: 1421.1472699\tbest: 1421.1357579 (8995)\ttotal: 5m 46s\tremaining: 58m 21s\n",
      "10000:\tlearn: 1102.5761578\ttest: 1102.5761578\ttest1: 1414.2175832\tbest: 1414.2175832 (10000)\ttotal: 6m 20s\tremaining: 57m 3s\n",
      "11000:\tlearn: 1089.1470582\ttest: 1089.1470582\ttest1: 1408.4543865\tbest: 1408.4516789 (10999)\ttotal: 6m 59s\tremaining: 56m 30s\n",
      "12000:\tlearn: 1077.0578476\ttest: 1077.0578476\ttest1: 1403.3934397\tbest: 1403.3934397 (12000)\ttotal: 7m 36s\tremaining: 55m 48s\n",
      "13000:\tlearn: 1067.0875922\ttest: 1067.0875922\ttest1: 1398.9662389\tbest: 1398.9643534 (12997)\ttotal: 8m 13s\tremaining: 55m 4s\n",
      "14000:\tlearn: 1056.9785160\ttest: 1056.9785160\ttest1: 1394.3075232\tbest: 1394.3027633 (13996)\ttotal: 8m 51s\tremaining: 54m 26s\n",
      "15000:\tlearn: 1048.7516440\ttest: 1048.7516440\ttest1: 1390.8427734\tbest: 1390.8373597 (14999)\ttotal: 9m 29s\tremaining: 53m 46s\n",
      "16000:\tlearn: 1040.5615316\ttest: 1040.5615316\ttest1: 1386.9544022\tbest: 1386.9535672 (15999)\ttotal: 10m 6s\tremaining: 53m 4s\n",
      "17000:\tlearn: 1034.2843813\ttest: 1034.2843813\ttest1: 1383.6489807\tbest: 1383.6446025 (16999)\ttotal: 10m 43s\tremaining: 52m 21s\n",
      "18000:\tlearn: 1029.9246530\ttest: 1029.9246530\ttest1: 1381.3237001\tbest: 1381.3214201 (17999)\ttotal: 11m 21s\tremaining: 51m 43s\n",
      "19000:\tlearn: 1026.0146123\ttest: 1026.0146123\ttest1: 1379.6763147\tbest: 1379.6546804 (18981)\ttotal: 11m 57s\tremaining: 50m 57s\n",
      "20000:\tlearn: 1020.9461624\ttest: 1020.9461624\ttest1: 1377.9025977\tbest: 1377.9025977 (20000)\ttotal: 12m 32s\tremaining: 50m 9s\n",
      "21000:\tlearn: 1011.8751650\ttest: 1011.8751650\ttest1: 1373.6751777\tbest: 1373.6730796 (20999)\ttotal: 13m 11s\tremaining: 49m 37s\n",
      "22000:\tlearn: 1005.3809907\ttest: 1005.3809907\ttest1: 1371.4385977\tbest: 1371.4167400 (21985)\ttotal: 13m 50s\tremaining: 49m 4s\n",
      "23000:\tlearn: 999.5025833\ttest: 999.5025833\ttest1: 1369.9060570\tbest: 1369.9060570 (23000)\ttotal: 14m 27s\tremaining: 48m 25s\n",
      "24000:\tlearn: 993.5981620\ttest: 993.5981620\ttest1: 1368.0791066\tbest: 1368.0669609 (23997)\ttotal: 15m 5s\tremaining: 47m 46s\n",
      "25000:\tlearn: 988.5594945\ttest: 988.5594945\ttest1: 1366.3807100\tbest: 1366.2727326 (24946)\ttotal: 15m 41s\tremaining: 47m 5s\n",
      "26000:\tlearn: 984.5552598\ttest: 984.5552598\ttest1: 1365.1841695\tbest: 1365.1598639 (25980)\ttotal: 16m 17s\tremaining: 46m 21s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 1365.083592\n",
      "bestIteration = 26141\n",
      "\n",
      "Shrink model to first 26142 iterations.\n",
      "Fold no 2/11\n",
      "0:\tlearn: 5939.2967162\ttest: 5939.2967162\ttest1: 5911.5236680\tbest: 5911.5236680 (0)\ttotal: 37.3ms\tremaining: 1h 2m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000:\tlearn: 1482.9596258\ttest: 1482.9596258\ttest1: 1449.5126267\tbest: 1449.5126267 (1000)\ttotal: 41.1s\tremaining: 1h 7m 49s\n",
      "2000:\tlearn: 1359.5443865\ttest: 1359.5443865\ttest1: 1363.2489602\tbest: 1363.2489602 (2000)\ttotal: 1m 21s\tremaining: 1h 6m 15s\n",
      "3000:\tlearn: 1308.2470381\ttest: 1308.2470381\ttest1: 1331.3300900\tbest: 1331.2804554 (2999)\ttotal: 1m 58s\tremaining: 1h 3m 44s\n",
      "4000:\tlearn: 1273.9127022\ttest: 1273.9127022\ttest1: 1314.9228174\tbest: 1314.9228174 (4000)\ttotal: 2m 34s\tremaining: 1h 1m 48s\n",
      "5000:\tlearn: 1246.2442232\ttest: 1246.2442232\ttest1: 1308.2334356\tbest: 1307.8441537 (4919)\ttotal: 3m 14s\tremaining: 1h 1m 30s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 1307.844154\n",
      "bestIteration = 4919\n",
      "\n",
      "Shrink model to first 4920 iterations.\n",
      "Fold no 3/11\n",
      "0:\tlearn: 5947.1894708\ttest: 5947.1894708\ttest1: 5831.0673272\tbest: 5831.0673272 (0)\ttotal: 41.5ms\tremaining: 1h 9m 12s\n",
      "1000:\tlearn: 1479.0925946\ttest: 1479.0925946\ttest1: 1468.7788008\tbest: 1468.7788008 (1000)\ttotal: 40.8s\tremaining: 1h 7m 19s\n",
      "2000:\tlearn: 1365.5145688\ttest: 1365.5145688\ttest1: 1399.3574046\tbest: 1399.3569922 (1999)\ttotal: 1m 19s\tremaining: 1h 5m 8s\n",
      "3000:\tlearn: 1320.6568516\ttest: 1320.6568516\ttest1: 1370.3541539\tbest: 1370.3541539 (3000)\ttotal: 1m 54s\tremaining: 1h 1m 31s\n",
      "4000:\tlearn: 1269.7965022\ttest: 1269.7965022\ttest1: 1339.0134476\tbest: 1339.0134476 (4000)\ttotal: 2m 30s\tremaining: 1h 21s\n",
      "5000:\tlearn: 1231.7085902\ttest: 1231.7085902\ttest1: 1318.5453885\tbest: 1318.5449613 (4999)\ttotal: 3m 8s\tremaining: 59m 35s\n",
      "6000:\tlearn: 1195.1774414\ttest: 1195.1774414\ttest1: 1308.0866681\tbest: 1308.0249326 (5997)\ttotal: 3m 48s\tremaining: 59m 36s\n",
      "7000:\tlearn: 1170.1853135\ttest: 1170.1853135\ttest1: 1299.5682851\tbest: 1299.5350532 (6998)\ttotal: 4m 27s\tremaining: 59m 17s\n",
      "8000:\tlearn: 1152.0893257\ttest: 1152.0893257\ttest1: 1293.2410794\tbest: 1293.2201094 (7997)\ttotal: 5m 7s\tremaining: 58m 51s\n",
      "9000:\tlearn: 1136.1009534\ttest: 1136.1009534\ttest1: 1288.1807846\tbest: 1288.1807846 (9000)\ttotal: 5m 46s\tremaining: 58m 25s\n",
      "10000:\tlearn: 1120.7421083\ttest: 1120.7421083\ttest1: 1281.1072513\tbest: 1281.1072513 (10000)\ttotal: 6m 25s\tremaining: 57m 50s\n",
      "11000:\tlearn: 1107.6754539\ttest: 1107.6754539\ttest1: 1276.5017148\tbest: 1276.5017148 (11000)\ttotal: 7m 4s\tremaining: 57m 12s\n",
      "12000:\tlearn: 1092.3398391\ttest: 1092.3398391\ttest1: 1270.9666650\tbest: 1270.9666650 (12000)\ttotal: 7m 42s\tremaining: 56m 29s\n",
      "13000:\tlearn: 1072.7004487\ttest: 1072.7004487\ttest1: 1264.0705997\tbest: 1264.0705997 (13000)\ttotal: 8m 22s\tremaining: 56m\n",
      "14000:\tlearn: 1056.7703289\ttest: 1056.7703289\ttest1: 1260.6040261\tbest: 1260.6040261 (14000)\ttotal: 9m 3s\tremaining: 55m 37s\n",
      "15000:\tlearn: 1045.1370338\ttest: 1045.1370338\ttest1: 1256.1544845\tbest: 1256.1541617 (14997)\ttotal: 9m 43s\tremaining: 55m 4s\n",
      "16000:\tlearn: 1038.7581514\ttest: 1038.7581514\ttest1: 1253.2091084\tbest: 1253.2081909 (15998)\ttotal: 10m 21s\tremaining: 54m 23s\n",
      "17000:\tlearn: 1034.1801413\ttest: 1034.1801413\ttest1: 1251.3167783\tbest: 1251.3162331 (16998)\ttotal: 11m 1s\tremaining: 53m 47s\n",
      "18000:\tlearn: 1031.1859137\ttest: 1031.1859137\ttest1: 1250.4818771\tbest: 1250.4712033 (17929)\ttotal: 11m 35s\tremaining: 52m 50s\n",
      "19000:\tlearn: 1028.6977074\ttest: 1028.6977074\ttest1: 1249.4909556\tbest: 1249.4908219 (18999)\ttotal: 12m 8s\tremaining: 51m 47s\n",
      "20000:\tlearn: 1020.8098432\ttest: 1020.8098432\ttest1: 1246.1892181\tbest: 1246.1892181 (20000)\ttotal: 12m 47s\tremaining: 51m 9s\n",
      "21000:\tlearn: 1015.5452134\ttest: 1015.5452134\ttest1: 1244.2016106\tbest: 1244.1766601 (20984)\ttotal: 13m 26s\tremaining: 50m 33s\n",
      "22000:\tlearn: 1010.3636268\ttest: 1010.3636268\ttest1: 1242.7119526\tbest: 1242.7110270 (21995)\ttotal: 14m 5s\tremaining: 49m 57s\n",
      "23000:\tlearn: 1006.6856522\ttest: 1006.6856522\ttest1: 1241.5971817\tbest: 1241.5737947 (22983)\ttotal: 14m 44s\tremaining: 49m 21s\n",
      "24000:\tlearn: 1002.6311388\ttest: 1002.6311388\ttest1: 1240.2158664\tbest: 1240.2158664 (24000)\ttotal: 15m 23s\tremaining: 48m 45s\n",
      "25000:\tlearn: 996.1264325\ttest: 996.1264325\ttest1: 1238.0304118\tbest: 1238.0304118 (25000)\ttotal: 16m 3s\tremaining: 48m 10s\n",
      "26000:\tlearn: 990.6708960\ttest: 990.6708960\ttest1: 1236.3512957\tbest: 1236.3511600 (25999)\ttotal: 16m 42s\tremaining: 47m 33s\n",
      "27000:\tlearn: 987.2514263\ttest: 987.2514263\ttest1: 1234.8144221\tbest: 1234.8135081 (26997)\ttotal: 17m 21s\tremaining: 46m 54s\n",
      "28000:\tlearn: 983.9278727\ttest: 983.9278727\ttest1: 1233.3841558\tbest: 1233.3841558 (28000)\ttotal: 17m 57s\tremaining: 46m 10s\n",
      "29000:\tlearn: 981.1014837\ttest: 981.1014837\ttest1: 1232.5783574\tbest: 1232.5783573 (28999)\ttotal: 18m 33s\tremaining: 45m 25s\n",
      "30000:\tlearn: 978.3954495\ttest: 978.3954495\ttest1: 1232.1984633\tbest: 1232.1783128 (29971)\ttotal: 19m 8s\tremaining: 44m 39s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 1232.023493\n",
      "bestIteration = 30401\n",
      "\n",
      "Shrink model to first 30402 iterations.\n",
      "Fold no 4/11\n",
      "0:\tlearn: 5960.1016548\ttest: 5960.1016548\ttest1: 5692.5411139\tbest: 5692.5411139 (0)\ttotal: 40.5ms\tremaining: 1h 7m 32s\n",
      "1000:\tlearn: 1488.5321066\ttest: 1488.5321066\ttest1: 1380.8445000\tbest: 1380.8445000 (1000)\ttotal: 41.5s\tremaining: 1h 8m 26s\n",
      "2000:\tlearn: 1365.0712220\ttest: 1365.0712220\ttest1: 1321.1335483\tbest: 1321.1335483 (2000)\ttotal: 1m 21s\tremaining: 1h 6m 38s\n",
      "3000:\tlearn: 1314.0307271\ttest: 1314.0307271\ttest1: 1297.5373234\tbest: 1297.4682742 (2997)\ttotal: 1m 59s\tremaining: 1h 4m 34s\n",
      "4000:\tlearn: 1281.0577046\ttest: 1281.0577046\ttest1: 1283.5692366\tbest: 1283.5596418 (3999)\ttotal: 2m 38s\tremaining: 1h 3m 30s\n",
      "5000:\tlearn: 1249.7978262\ttest: 1249.7978262\ttest1: 1270.2007689\tbest: 1270.2007689 (5000)\ttotal: 3m 18s\tremaining: 1h 2m 58s\n",
      "6000:\tlearn: 1213.7823032\ttest: 1213.7823032\ttest1: 1255.3508768\tbest: 1255.3508768 (6000)\ttotal: 3m 59s\tremaining: 1h 2m 31s\n",
      "7000:\tlearn: 1188.4579619\ttest: 1188.4579619\ttest1: 1244.6632312\tbest: 1244.6351143 (6988)\ttotal: 4m 39s\tremaining: 1h 1m 48s\n",
      "8000:\tlearn: 1168.5167377\ttest: 1168.5167377\ttest1: 1238.3311248\tbest: 1238.3311248 (8000)\ttotal: 5m 17s\tremaining: 1h 46s\n",
      "9000:\tlearn: 1152.0419250\ttest: 1152.0419250\ttest1: 1234.3164701\tbest: 1234.1485721 (8986)\ttotal: 5m 55s\tremaining: 59m 57s\n",
      "10000:\tlearn: 1138.7621192\ttest: 1138.7621192\ttest1: 1230.6829829\tbest: 1230.6812361 (9999)\ttotal: 6m 34s\tremaining: 59m 9s\n",
      "11000:\tlearn: 1126.9383667\ttest: 1126.9383667\ttest1: 1228.3069898\tbest: 1228.3052666 (10998)\ttotal: 7m 13s\tremaining: 58m 29s\n",
      "12000:\tlearn: 1115.9324251\ttest: 1115.9324251\ttest1: 1225.1865104\tbest: 1225.1442872 (11983)\ttotal: 7m 53s\tremaining: 57m 48s\n",
      "13000:\tlearn: 1106.4842257\ttest: 1106.4842257\ttest1: 1221.4880207\tbest: 1221.4870968 (12999)\ttotal: 8m 31s\tremaining: 57m 1s\n",
      "14000:\tlearn: 1100.7958426\ttest: 1100.7958426\ttest1: 1219.6215106\tbest: 1219.5861526 (13962)\ttotal: 9m 7s\tremaining: 56m\n",
      "15000:\tlearn: 1092.9944185\ttest: 1092.9944185\ttest1: 1217.1482154\tbest: 1217.1328916 (14991)\ttotal: 9m 43s\tremaining: 55m 8s\n",
      "16000:\tlearn: 1081.3948353\ttest: 1081.3948353\ttest1: 1212.5087872\tbest: 1212.5087872 (16000)\ttotal: 10m 23s\tremaining: 54m 34s\n",
      "17000:\tlearn: 1070.1065678\ttest: 1070.1065678\ttest1: 1208.2331873\tbest: 1208.2328269 (16998)\ttotal: 11m 2s\tremaining: 53m 53s\n",
      "18000:\tlearn: 1062.9441145\ttest: 1062.9441145\ttest1: 1205.3895761\tbest: 1205.3764406 (17995)\ttotal: 11m 41s\tremaining: 53m 17s\n",
      "19000:\tlearn: 1058.0472699\ttest: 1058.0472699\ttest1: 1203.9355442\tbest: 1203.9240115 (18997)\ttotal: 12m 19s\tremaining: 52m 33s\n",
      "20000:\tlearn: 1055.2475935\ttest: 1055.2475935\ttest1: 1203.0533925\tbest: 1203.0533925 (20000)\ttotal: 12m 55s\tremaining: 51m 43s\n",
      "21000:\tlearn: 1053.6913944\ttest: 1053.6913944\ttest1: 1202.6996841\tbest: 1202.6560229 (20988)\ttotal: 13m 33s\tremaining: 50m 58s\n",
      "22000:\tlearn: 1051.7356461\ttest: 1051.7356461\ttest1: 1201.8075692\tbest: 1201.7922001 (21994)\ttotal: 14m 11s\tremaining: 50m 18s\n",
      "23000:\tlearn: 1045.5721628\ttest: 1045.5721628\ttest1: 1199.2262216\tbest: 1199.2248603 (22999)\ttotal: 14m 50s\tremaining: 49m 41s\n",
      "24000:\tlearn: 1038.7954197\ttest: 1038.7954197\ttest1: 1196.6867402\tbest: 1196.6827704 (23998)\ttotal: 15m 30s\tremaining: 49m 6s\n",
      "25000:\tlearn: 1033.6362549\ttest: 1033.6362549\ttest1: 1194.6302871\tbest: 1194.6072290 (24986)\ttotal: 16m 10s\tremaining: 48m 30s\n",
      "26000:\tlearn: 1028.9775966\ttest: 1028.9775966\ttest1: 1192.8780979\tbest: 1192.8421925 (25975)\ttotal: 16m 49s\tremaining: 47m 53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27000:\tlearn: 1024.4639830\ttest: 1024.4639830\ttest1: 1191.4067587\tbest: 1191.3996278 (26996)\ttotal: 17m 29s\tremaining: 47m 17s\n",
      "28000:\tlearn: 1021.1972403\ttest: 1021.1972403\ttest1: 1190.4639795\tbest: 1190.4505282 (27991)\ttotal: 18m 9s\tremaining: 46m 40s\n",
      "29000:\tlearn: 1018.8561155\ttest: 1018.8561155\ttest1: 1189.6601017\tbest: 1189.6599354 (28999)\ttotal: 18m 48s\tremaining: 46m 3s\n",
      "30000:\tlearn: 1015.9947486\ttest: 1015.9947486\ttest1: 1188.6348757\tbest: 1188.6348757 (30000)\ttotal: 19m 27s\tremaining: 45m 24s\n",
      "31000:\tlearn: 1015.0277983\ttest: 1015.0277983\ttest1: 1188.1971375\tbest: 1188.1888542 (30997)\ttotal: 20m 3s\tremaining: 44m 38s\n",
      "32000:\tlearn: 1013.4424254\ttest: 1013.4424254\ttest1: 1187.5537784\tbest: 1187.5537784 (32000)\ttotal: 20m 42s\tremaining: 44m 1s\n",
      "33000:\tlearn: 1011.8554692\ttest: 1011.8554692\ttest1: 1186.8555108\tbest: 1186.8522705 (32991)\ttotal: 21m 22s\tremaining: 43m 22s\n",
      "34000:\tlearn: 1009.9055297\ttest: 1009.9055297\ttest1: 1185.7408193\tbest: 1185.7407876 (33998)\ttotal: 22m 1s\tremaining: 42m 45s\n",
      "35000:\tlearn: 1008.0432633\ttest: 1008.0432633\ttest1: 1184.6528929\tbest: 1184.6364593 (34996)\ttotal: 22m 41s\tremaining: 42m 8s\n",
      "36000:\tlearn: 1005.8091426\ttest: 1005.8091426\ttest1: 1183.5176580\tbest: 1183.5176580 (36000)\ttotal: 23m 21s\tremaining: 41m 30s\n",
      "37000:\tlearn: 1003.6408428\ttest: 1003.6408428\ttest1: 1182.4702266\tbest: 1182.4702266 (37000)\ttotal: 24m\tremaining: 40m 53s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 1181.817342\n",
      "bestIteration = 37773\n",
      "\n",
      "Shrink model to first 37774 iterations.\n",
      "Fold no 5/11\n",
      "0:\tlearn: 5962.8666044\ttest: 5962.8666044\ttest1: 5659.6284235\tbest: 5659.6284235 (0)\ttotal: 37.1ms\tremaining: 1h 1m 54s\n",
      "1000:\tlearn: 1499.7991488\ttest: 1499.7991488\ttest1: 1317.1885142\tbest: 1317.1885142 (1000)\ttotal: 41.3s\tremaining: 1h 8m 4s\n",
      "2000:\tlearn: 1378.3307940\ttest: 1378.3307940\ttest1: 1223.5963613\tbest: 1223.5963613 (2000)\ttotal: 1m 21s\tremaining: 1h 6m 31s\n",
      "3000:\tlearn: 1319.7558037\ttest: 1319.7558037\ttest1: 1182.7145531\tbest: 1182.7145531 (3000)\ttotal: 2m 1s\tremaining: 1h 5m 13s\n",
      "4000:\tlearn: 1277.1627125\ttest: 1277.1627125\ttest1: 1151.6647745\tbest: 1151.6647745 (4000)\ttotal: 2m 40s\tremaining: 1h 4m 11s\n",
      "5000:\tlearn: 1254.9948461\ttest: 1254.9948461\ttest1: 1135.8584801\tbest: 1135.8584801 (5000)\ttotal: 3m 18s\tremaining: 1h 2m 50s\n",
      "6000:\tlearn: 1232.1716271\ttest: 1232.1716271\ttest1: 1119.8578231\tbest: 1119.8476614 (5999)\ttotal: 3m 55s\tremaining: 1h 1m 25s\n",
      "7000:\tlearn: 1207.6152454\ttest: 1207.6152454\ttest1: 1100.9674034\tbest: 1100.9674034 (7000)\ttotal: 4m 32s\tremaining: 1h 16s\n",
      "8000:\tlearn: 1183.5450294\ttest: 1183.5450294\ttest1: 1083.1414094\tbest: 1083.1390372 (7999)\ttotal: 5m 12s\tremaining: 59m 56s\n",
      "9000:\tlearn: 1160.6009297\ttest: 1160.6009297\ttest1: 1068.4082577\tbest: 1068.4082577 (9000)\ttotal: 5m 53s\tremaining: 59m 33s\n",
      "10000:\tlearn: 1148.0448582\ttest: 1148.0448582\ttest1: 1063.9295513\tbest: 1063.9250526 (9996)\ttotal: 6m 32s\tremaining: 58m 49s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 1062.107024\n",
      "bestIteration = 10551\n",
      "\n",
      "Shrink model to first 10552 iterations.\n",
      "Fold no 6/11\n",
      "0:\tlearn: 5956.7136445\ttest: 5956.7136445\ttest1: 5725.4448209\tbest: 5725.4448209 (0)\ttotal: 39.5ms\tremaining: 1h 5m 52s\n",
      "1000:\tlearn: 1490.1576558\ttest: 1490.1576558\ttest1: 1390.0639705\tbest: 1390.0639705 (1000)\ttotal: 41.3s\tremaining: 1h 8m 8s\n",
      "2000:\tlearn: 1378.1115964\ttest: 1378.1115964\ttest1: 1321.7770021\tbest: 1321.7469525 (1999)\ttotal: 1m 21s\tremaining: 1h 6m 22s\n",
      "3000:\tlearn: 1322.0614655\ttest: 1322.0614655\ttest1: 1280.6772197\tbest: 1280.6772197 (3000)\ttotal: 2m\tremaining: 1h 4m 48s\n",
      "4000:\tlearn: 1278.2546039\ttest: 1278.2546039\ttest1: 1248.3526522\tbest: 1248.3270979 (3993)\ttotal: 2m 37s\tremaining: 1h 3m 7s\n",
      "5000:\tlearn: 1240.7474281\ttest: 1240.7474281\ttest1: 1220.1630715\tbest: 1220.1630715 (5000)\ttotal: 3m 15s\tremaining: 1h 1m 58s\n",
      "6000:\tlearn: 1209.3399046\ttest: 1209.3399046\ttest1: 1196.1047462\tbest: 1196.1047462 (6000)\ttotal: 3m 56s\tremaining: 1h 1m 38s\n",
      "7000:\tlearn: 1179.1880334\ttest: 1179.1880334\ttest1: 1170.8502326\tbest: 1170.8475416 (6996)\ttotal: 4m 36s\tremaining: 1h 1m 10s\n",
      "8000:\tlearn: 1150.6343885\ttest: 1150.6343885\ttest1: 1150.5373912\tbest: 1150.5244313 (7991)\ttotal: 5m 17s\tremaining: 1h 48s\n",
      "9000:\tlearn: 1130.7953876\ttest: 1130.7953876\ttest1: 1137.1041496\tbest: 1137.1041496 (9000)\ttotal: 5m 58s\tremaining: 1h 21s\n",
      "10000:\tlearn: 1120.3558970\ttest: 1120.3558970\ttest1: 1130.7528007\tbest: 1130.7431519 (9998)\ttotal: 6m 37s\tremaining: 59m 36s\n",
      "11000:\tlearn: 1113.2558997\ttest: 1113.2558997\ttest1: 1127.2166418\tbest: 1127.2166418 (11000)\ttotal: 7m 17s\tremaining: 58m 56s\n",
      "12000:\tlearn: 1106.9481687\ttest: 1106.9481687\ttest1: 1124.2980003\tbest: 1124.2977073 (11996)\ttotal: 7m 55s\tremaining: 58m 4s\n",
      "13000:\tlearn: 1100.3237479\ttest: 1100.3237479\ttest1: 1120.9076121\tbest: 1120.8854395 (12977)\ttotal: 8m 32s\tremaining: 57m 9s\n",
      "14000:\tlearn: 1094.9070207\ttest: 1094.9070207\ttest1: 1118.1902493\tbest: 1118.1901955 (13999)\ttotal: 9m 9s\tremaining: 56m 12s\n",
      "15000:\tlearn: 1089.5293039\ttest: 1089.5293039\ttest1: 1115.2928633\tbest: 1115.2919098 (14998)\ttotal: 9m 46s\tremaining: 55m 22s\n",
      "16000:\tlearn: 1085.3908192\ttest: 1085.3908192\ttest1: 1113.2454028\tbest: 1113.1951319 (15952)\ttotal: 10m 22s\tremaining: 54m 29s\n",
      "17000:\tlearn: 1082.6783766\ttest: 1082.6783766\ttest1: 1111.9087489\tbest: 1111.9087489 (17000)\ttotal: 11m 1s\tremaining: 53m 49s\n",
      "18000:\tlearn: 1078.3375218\ttest: 1078.3375218\ttest1: 1109.7376638\tbest: 1109.7278804 (17984)\ttotal: 11m 40s\tremaining: 53m 10s\n",
      "19000:\tlearn: 1074.4862610\ttest: 1074.4862610\ttest1: 1107.4883645\tbest: 1107.4740919 (18995)\ttotal: 12m 16s\tremaining: 52m 19s\n",
      "20000:\tlearn: 1071.9414066\ttest: 1071.9414066\ttest1: 1106.1869912\tbest: 1106.1866469 (19995)\ttotal: 12m 51s\tremaining: 51m 24s\n",
      "21000:\tlearn: 1068.6773028\ttest: 1068.6773028\ttest1: 1104.9108758\tbest: 1104.9107611 (20997)\ttotal: 13m 28s\tremaining: 50m 39s\n",
      "22000:\tlearn: 1065.4877776\ttest: 1065.4877776\ttest1: 1103.5917929\tbest: 1103.5886047 (21999)\ttotal: 14m 3s\tremaining: 49m 49s\n",
      "23000:\tlearn: 1057.7453487\ttest: 1057.7453487\ttest1: 1099.8533898\tbest: 1099.8526252 (22997)\ttotal: 14m 40s\tremaining: 49m 8s\n",
      "24000:\tlearn: 1052.2245406\ttest: 1052.2245406\ttest1: 1097.1191103\tbest: 1097.1188739 (23999)\ttotal: 15m 17s\tremaining: 48m 25s\n",
      "25000:\tlearn: 1046.9250925\ttest: 1046.9250925\ttest1: 1094.8609848\tbest: 1094.8609848 (25000)\ttotal: 15m 54s\tremaining: 47m 44s\n",
      "26000:\tlearn: 1042.4305097\ttest: 1042.4305097\ttest1: 1092.9442983\tbest: 1092.9380089 (25990)\ttotal: 16m 32s\tremaining: 47m 3s\n",
      "27000:\tlearn: 1038.7195597\ttest: 1038.7195597\ttest1: 1091.1106608\tbest: 1091.1095934 (26988)\ttotal: 17m 10s\tremaining: 46m 27s\n",
      "28000:\tlearn: 1036.4935640\ttest: 1036.4935640\ttest1: 1090.2796970\tbest: 1090.2796970 (28000)\ttotal: 17m 48s\tremaining: 45m 47s\n",
      "29000:\tlearn: 1031.8910477\ttest: 1031.8910477\ttest1: 1088.0044549\tbest: 1088.0043880 (28999)\ttotal: 18m 26s\tremaining: 45m 7s\n",
      "30000:\tlearn: 1024.0633038\ttest: 1024.0633038\ttest1: 1083.9332612\tbest: 1083.9332612 (30000)\ttotal: 19m 3s\tremaining: 44m 26s\n",
      "31000:\tlearn: 1017.0729574\ttest: 1017.0729574\ttest1: 1081.0710320\tbest: 1081.0710320 (31000)\ttotal: 19m 40s\tremaining: 43m 48s\n",
      "32000:\tlearn: 1011.4474642\ttest: 1011.4474642\ttest1: 1078.9735640\tbest: 1078.9665769 (31999)\ttotal: 20m 20s\tremaining: 43m 12s\n",
      "33000:\tlearn: 1006.0371038\ttest: 1006.0371038\ttest1: 1077.5894191\tbest: 1077.5488790 (32978)\ttotal: 20m 59s\tremaining: 42m 36s\n",
      "34000:\tlearn: 1000.6019218\ttest: 1000.6019218\ttest1: 1075.6834901\tbest: 1075.6782997 (33998)\ttotal: 21m 39s\tremaining: 42m 1s\n",
      "35000:\tlearn: 995.0727908\ttest: 995.0727908\ttest1: 1073.5207216\tbest: 1073.5207216 (35000)\ttotal: 22m 19s\tremaining: 41m 26s\n",
      "36000:\tlearn: 988.8650782\ttest: 988.8650782\ttest1: 1071.2730120\tbest: 1071.2674017 (35994)\ttotal: 22m 59s\tremaining: 40m 52s\n",
      "37000:\tlearn: 984.0596386\ttest: 984.0596386\ttest1: 1069.6924289\tbest: 1069.6915407 (36995)\ttotal: 23m 39s\tremaining: 40m 16s\n",
      "38000:\tlearn: 981.1820615\ttest: 981.1820615\ttest1: 1068.6370194\tbest: 1068.6361488 (37996)\ttotal: 24m 18s\tremaining: 39m 39s\n",
      "39000:\tlearn: 978.1514211\ttest: 978.1514211\ttest1: 1067.4279186\tbest: 1067.4151485 (38986)\ttotal: 24m 57s\tremaining: 39m 2s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 1067.365292\n",
      "bestIteration = 39112\n",
      "\n",
      "Shrink model to first 39113 iterations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold no 7/11\n",
      "0:\tlearn: 5932.7350900\ttest: 5932.7350900\ttest1: 5971.1124461\tbest: 5971.1124461 (0)\ttotal: 37.8ms\tremaining: 1h 3m 4s\n",
      "1000:\tlearn: 1473.0472206\ttest: 1473.0472206\ttest1: 1575.3182775\tbest: 1575.3182775 (1000)\ttotal: 41.6s\tremaining: 1h 8m 34s\n",
      "2000:\tlearn: 1358.4759856\ttest: 1358.4759856\ttest1: 1479.1779447\tbest: 1479.1779447 (2000)\ttotal: 1m 21s\tremaining: 1h 6m 25s\n",
      "3000:\tlearn: 1312.5560355\ttest: 1312.5560355\ttest1: 1445.1848095\tbest: 1445.1848095 (3000)\ttotal: 1m 59s\tremaining: 1h 4m 13s\n",
      "4000:\tlearn: 1260.8131960\ttest: 1260.8131960\ttest1: 1405.9761922\tbest: 1405.9761922 (4000)\ttotal: 2m 38s\tremaining: 1h 3m 19s\n",
      "5000:\tlearn: 1218.5421290\ttest: 1218.5421290\ttest1: 1379.0988948\tbest: 1379.0988948 (5000)\ttotal: 3m 17s\tremaining: 1h 2m 35s\n",
      "6000:\tlearn: 1189.5025393\ttest: 1189.5025393\ttest1: 1365.3293475\tbest: 1365.3293475 (6000)\ttotal: 3m 57s\tremaining: 1h 2m 3s\n",
      "7000:\tlearn: 1168.6081535\ttest: 1168.6081535\ttest1: 1357.3304783\tbest: 1357.2984471 (6993)\ttotal: 4m 38s\tremaining: 1h 1m 33s\n",
      "8000:\tlearn: 1150.7604084\ttest: 1150.7604084\ttest1: 1349.3553806\tbest: 1349.3255128 (7998)\ttotal: 5m 17s\tremaining: 1h 49s\n",
      "9000:\tlearn: 1135.7553774\ttest: 1135.7553774\ttest1: 1341.5194509\tbest: 1341.5194509 (9000)\ttotal: 5m 55s\tremaining: 59m 50s\n",
      "10000:\tlearn: 1121.2766920\ttest: 1121.2766920\ttest1: 1333.4632703\tbest: 1333.4632703 (10000)\ttotal: 6m 33s\tremaining: 59m 1s\n",
      "11000:\tlearn: 1108.5235183\ttest: 1108.5235183\ttest1: 1326.1784943\tbest: 1326.1557541 (10993)\ttotal: 7m 10s\tremaining: 58m 4s\n",
      "12000:\tlearn: 1098.2494936\ttest: 1098.2494936\ttest1: 1320.3436159\tbest: 1320.3288172 (11991)\ttotal: 7m 49s\tremaining: 57m 20s\n",
      "13000:\tlearn: 1088.8248225\ttest: 1088.8248225\ttest1: 1314.4699204\tbest: 1314.4565366 (12979)\ttotal: 8m 26s\tremaining: 56m 31s\n",
      "14000:\tlearn: 1082.0008892\ttest: 1082.0008892\ttest1: 1311.3119116\tbest: 1311.2966571 (13995)\ttotal: 9m 2s\tremaining: 55m 34s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 1311.073828\n",
      "bestIteration = 14113\n",
      "\n",
      "Shrink model to first 14114 iterations.\n",
      "Fold no 8/11\n",
      "0:\tlearn: 5956.2036534\ttest: 5956.2036534\ttest1: 5731.6147977\tbest: 5731.6147977 (0)\ttotal: 37.2ms\tremaining: 1h 1m 58s\n",
      "1000:\tlearn: 1476.9793105\ttest: 1476.9793105\ttest1: 1545.2679099\tbest: 1545.2679099 (1000)\ttotal: 41.4s\tremaining: 1h 8m 11s\n",
      "2000:\tlearn: 1351.4487728\ttest: 1351.4487728\ttest1: 1447.7808376\tbest: 1447.7808376 (2000)\ttotal: 1m 21s\tremaining: 1h 6m 17s\n",
      "3000:\tlearn: 1291.6626307\ttest: 1291.6626307\ttest1: 1412.7195265\tbest: 1412.6435353 (2997)\ttotal: 1m 59s\tremaining: 1h 4m 34s\n",
      "4000:\tlearn: 1243.2468023\ttest: 1243.2468023\ttest1: 1390.8136336\tbest: 1390.8136336 (4000)\ttotal: 2m 40s\tremaining: 1h 4m 4s\n",
      "5000:\tlearn: 1205.1724454\ttest: 1205.1724454\ttest1: 1369.9644464\tbest: 1369.9642779 (4998)\ttotal: 3m 20s\tremaining: 1h 3m 28s\n",
      "6000:\tlearn: 1178.6646357\ttest: 1178.6646357\ttest1: 1354.6265188\tbest: 1354.6265188 (6000)\ttotal: 4m\tremaining: 1h 2m 42s\n",
      "7000:\tlearn: 1163.1807772\ttest: 1163.1807772\ttest1: 1346.9932592\tbest: 1346.9875631 (6991)\ttotal: 4m 39s\tremaining: 1h 1m 54s\n",
      "8000:\tlearn: 1152.2219928\ttest: 1152.2219928\ttest1: 1342.4200156\tbest: 1342.4200156 (8000)\ttotal: 5m 18s\tremaining: 1h 1m 6s\n",
      "9000:\tlearn: 1143.3822394\ttest: 1143.3822394\ttest1: 1340.2295272\tbest: 1340.2267808 (8996)\ttotal: 5m 58s\tremaining: 1h 20s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 1340.199774\n",
      "bestIteration = 9104\n",
      "\n",
      "Shrink model to first 9105 iterations.\n",
      "Fold no 9/11\n",
      "0:\tlearn: 5951.4528984\ttest: 5951.4528984\ttest1: 5782.4390145\tbest: 5782.4390145 (0)\ttotal: 41.4ms\tremaining: 1h 8m 54s\n",
      "1000:\tlearn: 1487.2186959\ttest: 1487.2186959\ttest1: 1433.2221401\tbest: 1433.2221401 (1000)\ttotal: 41.6s\tremaining: 1h 8m 34s\n",
      "2000:\tlearn: 1369.6019642\ttest: 1369.6019642\ttest1: 1331.3213051\tbest: 1331.3213051 (2000)\ttotal: 1m 22s\tremaining: 1h 7m 2s\n",
      "3000:\tlearn: 1320.4017762\ttest: 1320.4017762\ttest1: 1296.0387082\tbest: 1296.0387082 (3000)\ttotal: 1m 58s\tremaining: 1h 4m 4s\n",
      "4000:\tlearn: 1270.3577656\ttest: 1270.3577656\ttest1: 1257.0000974\tbest: 1257.0000974 (4000)\ttotal: 2m 38s\tremaining: 1h 3m 14s\n",
      "5000:\tlearn: 1236.7175152\ttest: 1236.7175152\ttest1: 1235.2987138\tbest: 1235.2885165 (4992)\ttotal: 3m 17s\tremaining: 1h 2m 27s\n",
      "6000:\tlearn: 1211.4807126\ttest: 1211.4807126\ttest1: 1219.7311161\tbest: 1219.7311161 (6000)\ttotal: 3m 56s\tremaining: 1h 1m 45s\n",
      "7000:\tlearn: 1184.2913771\ttest: 1184.2913771\ttest1: 1203.5848200\tbest: 1203.5828106 (6998)\ttotal: 4m 36s\tremaining: 1h 1m 13s\n",
      "8000:\tlearn: 1160.4722011\ttest: 1160.4722011\ttest1: 1190.5323795\tbest: 1190.5290585 (7995)\ttotal: 5m 16s\tremaining: 1h 41s\n",
      "9000:\tlearn: 1143.1385932\ttest: 1143.1385932\ttest1: 1181.8064978\tbest: 1181.8064978 (9000)\ttotal: 5m 56s\tremaining: 1h 8s\n",
      "10000:\tlearn: 1127.2081251\ttest: 1127.2081251\ttest1: 1173.4191756\tbest: 1173.4191337 (9999)\ttotal: 6m 36s\tremaining: 59m 31s\n",
      "11000:\tlearn: 1114.2672349\ttest: 1114.2672349\ttest1: 1166.0755748\tbest: 1166.0755748 (11000)\ttotal: 7m 16s\tremaining: 58m 52s\n",
      "12000:\tlearn: 1100.0783906\ttest: 1100.0783906\ttest1: 1160.6217591\tbest: 1160.6217591 (12000)\ttotal: 7m 56s\tremaining: 58m 16s\n",
      "13000:\tlearn: 1089.8930978\ttest: 1089.8930978\ttest1: 1157.1187593\tbest: 1157.1187593 (13000)\ttotal: 8m 35s\tremaining: 57m 32s\n",
      "14000:\tlearn: 1085.3747199\ttest: 1085.3747199\ttest1: 1153.3024341\tbest: 1153.2908996 (13999)\ttotal: 9m 11s\tremaining: 56m 27s\n",
      "15000:\tlearn: 1081.7504456\ttest: 1081.7504456\ttest1: 1150.1010826\tbest: 1150.0652307 (14960)\ttotal: 9m 47s\tremaining: 55m 26s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 1149.95371\n",
      "bestIteration = 15088\n",
      "\n",
      "Shrink model to first 15089 iterations.\n",
      "Fold no 10/11\n",
      "0:\tlearn: 5943.9486735\ttest: 5943.9486735\ttest1: 5866.7212517\tbest: 5866.7212517 (0)\ttotal: 41.4ms\tremaining: 1h 9m 1s\n",
      "1000:\tlearn: 1486.8734693\ttest: 1486.8734693\ttest1: 1486.7673506\tbest: 1486.7673506 (1000)\ttotal: 41.3s\tremaining: 1h 8m 6s\n",
      "2000:\tlearn: 1372.7674780\ttest: 1372.7674780\ttest1: 1391.3352657\tbest: 1391.3352657 (2000)\ttotal: 1m 20s\tremaining: 1h 5m 55s\n",
      "3000:\tlearn: 1314.7748595\ttest: 1314.7748595\ttest1: 1350.4255800\tbest: 1350.4255800 (3000)\ttotal: 1m 58s\tremaining: 1h 3m 46s\n",
      "4000:\tlearn: 1262.5595307\ttest: 1262.5595307\ttest1: 1317.3676319\tbest: 1317.3676319 (4000)\ttotal: 2m 38s\tremaining: 1h 3m 21s\n",
      "5000:\tlearn: 1224.3763370\ttest: 1224.3763370\ttest1: 1299.9915058\tbest: 1299.9915058 (5000)\ttotal: 3m 17s\tremaining: 1h 2m 32s\n",
      "6000:\tlearn: 1198.4943516\ttest: 1198.4943516\ttest1: 1288.4587486\tbest: 1288.4531946 (5995)\ttotal: 3m 56s\tremaining: 1h 1m 49s\n",
      "7000:\tlearn: 1181.2442176\ttest: 1181.2442176\ttest1: 1281.3819117\tbest: 1281.3039033 (6985)\ttotal: 4m 35s\tremaining: 1h 58s\n",
      "8000:\tlearn: 1166.7736295\ttest: 1166.7736295\ttest1: 1275.4791588\tbest: 1275.4791588 (8000)\ttotal: 5m 13s\tremaining: 1h 10s\n",
      "9000:\tlearn: 1147.6552510\ttest: 1147.6552510\ttest1: 1265.3729512\tbest: 1265.3672321 (8999)\ttotal: 5m 54s\tremaining: 59m 41s\n",
      "10000:\tlearn: 1129.0648041\ttest: 1129.0648041\ttest1: 1256.5397900\tbest: 1256.5376305 (9998)\ttotal: 6m 34s\tremaining: 59m 6s\n",
      "11000:\tlearn: 1114.0787099\ttest: 1114.0787099\ttest1: 1250.5368343\tbest: 1250.5160254 (10981)\ttotal: 7m 13s\tremaining: 58m 27s\n",
      "12000:\tlearn: 1101.8964341\ttest: 1101.8964341\ttest1: 1246.7334316\tbest: 1246.7334316 (12000)\ttotal: 7m 53s\tremaining: 57m 49s\n",
      "13000:\tlearn: 1088.6764248\ttest: 1088.6764248\ttest1: 1243.4700918\tbest: 1243.4700918 (13000)\ttotal: 8m 33s\tremaining: 57m 13s\n",
      "14000:\tlearn: 1078.6663676\ttest: 1078.6663676\ttest1: 1239.9560414\tbest: 1239.9557365 (13999)\ttotal: 9m 14s\tremaining: 56m 44s\n",
      "15000:\tlearn: 1071.4402707\ttest: 1071.4402707\ttest1: 1236.8118777\tbest: 1236.8118248 (14998)\ttotal: 9m 54s\tremaining: 56m 5s\n",
      "16000:\tlearn: 1065.5387816\ttest: 1065.5387816\ttest1: 1234.2390547\tbest: 1234.2390547 (16000)\ttotal: 10m 34s\tremaining: 55m 32s\n",
      "17000:\tlearn: 1058.5091082\ttest: 1058.5091082\ttest1: 1230.9117652\tbest: 1230.9117652 (17000)\ttotal: 11m 17s\tremaining: 55m 9s\n",
      "18000:\tlearn: 1049.5334692\ttest: 1049.5334692\ttest1: 1227.1115992\tbest: 1227.1115992 (18000)\ttotal: 12m 5s\tremaining: 55m 3s\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(layer1_models)):\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    print('\\n')\n",
    "    name = layer1_names[i]\n",
    "    model = layer1_models[i]\n",
    "    folds = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=2333)\n",
    "    print('Training %s' %name)\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train[features], train['tradeMoney'])):\n",
    "        print('Fold no %i/%i'%(fold_+1,N_FOLDS))\n",
    "        trn_data = train[features].iloc[trn_idx]\n",
    "        trn_label = train['tradeMoney'].iloc[trn_idx]\n",
    "        val_data = train[features].iloc[val_idx]\n",
    "        val_label = train['tradeMoney'].iloc[val_idx]\n",
    "        if 'ada' in name:\n",
    "            model.fit(X=trn_data, y=trn_label)\n",
    "        else:\n",
    "            model.fit(X=trn_data, y=trn_label,\n",
    "                     eval_set=[(trn_data, trn_label), (val_data, val_label)],\n",
    "                     verbose=1000,\n",
    "                     early_stopping_rounds=200)\n",
    "\n",
    "        oof_train[val_idx,i] = model.predict(val_data)\n",
    "        oof_test[:,i] += model.predict(test[features])/N_FOLDS\n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = features\n",
    "        fold_importance_df[\"importance\"] = model.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "    score = r2_score(target, oof_train[:,i])\n",
    "    layer1_score.append(score)\n",
    "    feature_importance.append(feature_importance_df)\n",
    "    print('Training CV score: %.5f' %score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exchange two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds=np.loadtxt('lgb_oof_preds-0.90448.csv',delimiter=',')\n",
    "sub_preds=np.loadtxt('lgb_sub_preds-0.90448.csv',delimiter=',')\n",
    "\n",
    "\n",
    "score = r2_score(target, oof_preds)\n",
    "print('Training CV score for LGB: %.5f' %score)\n",
    "layer1_names.append('LGB')\n",
    "layer1_score.append(score)\n",
    "\n",
    "oof_preds = oof_preds[:, np.newaxis]\n",
    "sub_preds = sub_preds[:, np.newaxis]\n",
    "oof_train = np.hstack((oof_train, oof_preds))\n",
    "oof_test = np.hstack((oof_test, sub_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds=np.loadtxt('xgb_oof_preds-0.886.csv',delimiter=',')\n",
    "sub_preds=np.loadtxt('xgb_sub_preds-0.886.csv',delimiter=',')\n",
    "\n",
    "score = r2_score(target, oof_preds)\n",
    "print('Training CV score for XGB1: %.5f' %score)\n",
    "layer1_names.append('XGB1')\n",
    "layer1_score.append(score)\n",
    "\n",
    "oof_preds = oof_preds[:, np.newaxis]\n",
    "sub_preds = sub_preds[:, np.newaxis]\n",
    "oof_train = np.hstack((oof_train, oof_preds))\n",
    "oof_test = np.hstack((oof_test, sub_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds=np.loadtxt('xgb_oof_preds-0.89566.csv',delimiter=',')\n",
    "sub_preds=np.loadtxt('xgb_sub_preds-0.89566.csv',delimiter=',')\n",
    "\n",
    "score = r2_score(target, oof_preds)\n",
    "print('Training CV score for XGB2: %.5f' %score)\n",
    "layer1_names.append('XGB2')\n",
    "layer1_score.append(score)\n",
    "\n",
    "oof_preds = oof_preds[:, np.newaxis]\n",
    "sub_preds = sub_preds[:, np.newaxis]\n",
    "oof_train = np.hstack((oof_train, oof_preds))\n",
    "oof_test = np.hstack((oof_test, sub_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b8961f81ec04b90554d5e36d0177cf0645d855a6"
   },
   "source": [
    "#### Layer 1 summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f442a72a9eb2c91add955488c3c209e2e14697f7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print first layer result\n",
    "layer1 = pd.DataFrame()\n",
    "layer1['models'] = layer1_names\n",
    "layer1['CV_score'] = layer1_score\n",
    "layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "01896a7b9e3031e39f208d552fee686181b6ffa9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer1_corr = pd.DataFrame()\n",
    "for i in range(len(layer1_names)):\n",
    "    layer1_corr[layer1_names[i]] = oof_train[:,i]\n",
    "layer1_corr['target'] = target\n",
    "colormap = plt.cm.RdBu\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(layer1_corr.astype(float).corr(), linewidths=0.1, vmax=1.0, vmin=-1., square=True, cmap=colormap, linecolor='white', annot=True)\n",
    "plt.title('Pair-wise correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d1025058574c71118ff479af923547a4036a3fc"
   },
   "source": [
    "### Second layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "18dfb0e87854e90ae33f0933af01065062300c23"
   },
   "outputs": [],
   "source": [
    "# Setup the model\n",
    "ridge = Ridge(alpha=0.5)#, fit_intercept=False)\n",
    "lasso = Lasso(alpha=0.5)\n",
    "lars = Lars(fit_intercept=False, positive=True)\n",
    "layer2_models = [lars]#[ridge]# lasso]\n",
    "layer2_names = ['Lars']#['ridge'] #, 'lasso']\n",
    "#params_grid = {'alpha':[0.05,0.1,0.4,1.0]}\n",
    "\n",
    "# Setup to record result\n",
    "train_pred = np.zeros(len(train))\n",
    "test_pred = np.zeros(len(test))\n",
    "\n",
    "layer2 = pd.DataFrame()\n",
    "layer2['models'] = layer2_names\n",
    "layer2_score = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75059c60d4056e1caf4018938e2d7f7512a6314d"
   },
   "outputs": [],
   "source": [
    "# For regression\n",
    "\n",
    "for i in range(len(layer2_models)):\n",
    "    print('\\n')\n",
    "    name = layer2_names[i]\n",
    "    model = layer2_models[i]\n",
    "    print('Training %s' %name)\n",
    "    #model, score = do_regressor((oof_train, target), model=model, parameters=params_grid)\n",
    "    model.fit(oof_train, target)\n",
    "    score = r2_score(target, model.predict(oof_train))\n",
    "    train_pred += model.predict(oof_train)/len(layer2_models)\n",
    "    test_pred += model.predict(oof_test)/len(layer2_models)\n",
    "    layer2_score.append(score)\n",
    "    print('Training score: %.5f' % score)\n",
    "\n",
    "#layer2['CV score'] = layer2_score\n",
    "#layer2\n",
    "\n",
    "layer2_coef = pd.DataFrame()\n",
    "layer2_coef['Name'] = layer1_names\n",
    "layer2_coef['Coefficient'] = model.coef_\n",
    "#layer2_coef['Coefficient'] = coef\n",
    "layer2_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "e41a01c2e2f256ba00678f0bfa3f93cbfe3d33b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Taking average\\ntrain_pred = np.mean(oof_train, axis=1)\\ntest_pred = np.mean(oof_test, axis=1)\\nprint('Training score: %.5f' %mean_squared_error(train_pred, target)**0.5)\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Taking average\n",
    "train_pred = np.mean(oof_train, axis=1)\n",
    "test_pred = np.mean(oof_test, axis=1)\n",
    "print('Training score: %.5f' %mean_squared_error(train_pred, target)**0.5)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "9cfb750ba870534ffbeeed38950fe9c51b6b3e8b"
   },
   "outputs": [],
   "source": [
    "#np.sum(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "29066ed554eb1dc196760fb8e17fc52e200b75c4",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(range(len(test_pred)), np.sort(test_pred))\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('Loyalty Score', fontsize=12)\n",
    "plt.title('Loyalty score before scaling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "037b8320701f902bc2ee267984139a77fb6f9ade"
   },
   "outputs": [],
   "source": [
    "# Refit to the target\n",
    "train_scaler = StandardScaler()\n",
    "#train_scaler.fit(target.values.reshape(-1,1))\n",
    "#test_pred = train_scaler.inverse_transform(test_pred.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61f5c9202172b3e6b90fd9bc2c1982219e6ecd64"
   },
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "e6cf79c20304e868c09dfd7d6610fc3eb32853ab"
   },
   "outputs": [],
   "source": [
    "#sub_df = pd.DataFrame({\"card_id\":test[\"card_id\"].values})\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv')\n",
    "sample_submission[\"target\"] = test_pred\n",
    "sample_submission.to_csv(\"model-stacking-ensemble-low_features-StratifiedKFold11.csv \", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "70e785327f87a8416fcf8afa29ae1f1c2c14914d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sub_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-ed78c58e2591>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loyalty Score'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loyalty score after scaling'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sub_df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(range(sub_df.shape[0]), np.sort(sub_df['target'].values))\n",
    "plt.xlabel('index', fontsize=12)\n",
    "plt.ylabel('Loyalty Score', fontsize=12)\n",
    "plt.title('Loyalty score after scaling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
